\documentclass[11pt]{article}
\usepackage{amsmath, amsthm, amsfonts, graphicx, color, caption}

\setlength{\topmargin}{0 mm}
\setlength{\oddsidemargin}{5 mm}
\setlength{\evensidemargin}{5 mm}
\setlength{\textwidth}{150 mm}
\setlength{\textheight}{210 mm}

\include{macros}

\begin{document}

\title{Solving the quantum control problem using the adjoint state method}
\author{N. Anders Petersson}
\date{\today}
\maketitle

%%%%%%%%%%%%%%%
\section{ODE constrained minimization of a functional}
The wave function $\Psi(t)$ is governed by the normalized Schroedinger equation,
\[
i\dot{\Psi} = H\Psi,\quad H=H^*,\quad t\geq 0,
\]
where time has been scaled by $\hbar$.  We write this system of ordinary differential equations
(ODEs) in the form (the state equation),
\begin{equation}\label{eq:ode}
  \dot{\Psi} + A(t,\alpha)\Psi =0,\quad t\in[0,T], \quad \Psi(0) = \Psi_0,\quad A^* = -A,
\end{equation}
where $\Psi(t)\in {\mathbb C}^D$, $A\in {\mathbb C}^{D\times D} $. Let
\begin{align}
  A(t,\alpha) &:= iH(t,\alpha) = i\left(H_0 + p(t,\alpha)H_{c1} + i q(t,\alpha)H_{c2}\right),\\
  %
  H_0&=H_0^*, \quad H_{c1} = H_{c1}^*, \quad H_{c2} = -H_{c2}^*.
\end{align}
Here, $p\in \mathbb{R}$ and $q\in \mathbb{R}$ are given control functions that depend on time and the
parameter vector $\alpha\in{\mathbb R}^M$, with components $\alpha_k$, $k=1,2,\ldots,M$.

The solution of the system of ODEs \eqref{eq:ode} depends implicitly on the parameter vector
$\alpha$ throught the matrix $A(t,\alpha)$. Thus, $\Psi(t)=\Psi^\alpha(t)$.

The quantum control problem can be cast into a minimization problem for a real-valued functional
$J(\alpha)$ under the constraint that $\Psi^\alpha$ satisfies \eqref{eq:ode}. To illustrate the idea,
consider the simple functional
\begin{equation}\label{eq_func-simple}
  J(\alpha) := g(\Psi^\alpha) = \int_0^T |\Psi^\alpha(\tau) - d(\tau)|^2\, d\tau,
\end{equation}
where the function $d(t)$ is given. We want to find
\[
\alpha:\enskip \min_\alpha  J(\alpha),\quad \mbox{$\Psi^\alpha(t)$ satisfies \eqref{eq:ode}} 
\]

We define a scalar product for functions $u$ and $v$ in ${\mathbb C}^D \times [0,T]$,
\[
(u,v) = \int_0^T \langle u(\tau), v(\tau)\rangle\, d\tau,\quad \langle u, v\rangle =
\sum_{j=1}^D \bar{u}_j v_j.
\]
The functional \eqref{eq_func-simple} can then be written
\[
g(\Psi^\alpha) = (\Psi^\alpha - d, \Psi^\alpha - d).
\]
Note that $d(t)$ is independent of $\alpha$. Each component of the gradient of the objective
functional satisfies
\begin{equation}\label{eq:grad}
  \frac{\partial J}{\partial \alpha_k} =
%
  \left(\frac{\partial\Psi^\alpha}{\partial \alpha_k}, \Psi^\alpha-d \right) +
  \left(\Psi^\alpha-d, \frac{\partial\Psi^\alpha}{\partial \alpha_k} \right) \\
  %
  = 2\, {\rm Re} \left(
\frac{\partial\Psi^\alpha}{\partial \alpha_k}, \Psi^\alpha-d \right)
\end{equation}
By differentiating the state equation \eqref{eq:ode} with respect to
$\alpha_k$ and introducing the function $\Phi_k(t) = \partial \Psi^\alpha/\partial \alpha_k(t)$,
\begin{equation}\label{eq:state}
\dot{\Phi}_k +
A(t,\alpha) \Phi_k = f_k(t,\alpha),\quad
t\in[0,T], \quad \Phi(0) = 0,\quad f_k(t,\alpha) := - \frac{\partial A}{\partial \alpha_k}\,\Psi^\alpha(t).
\end{equation}
Thus, $\Phi_k$ satisfies a state equation with the forcing function $f_k$. Inserted into
\eqref{eq:grad}, the formula for the gradient becomes
\begin{equation}\label{eq:grad-formula}
\frac{\partial J}{\partial \alpha_k} = 2\, {\rm Re} \left( \Phi_k, \Psi^\alpha - d \right)
\end{equation}
Using the above approach, we can compute the gradient with respect to all $M$ parameters by solving
the state equation \eqref{eq:ode} for $\Psi^\alpha$, followed by solving \eqref{eq:state} for
$\Phi_k$, $k=1,2,\ldots,M$. The gradient is finally obtained by evaluating \eqref{eq:grad-formula}. Hence,
each evaluation of the gradient requires $M+1$ systems of ODEs to be solved. We proceed by deriving a
significantly more efficient alternative based on solving the adjoint system of ODEs.

\subsection{The adjoint problem}
Consider the adjoint state equation,
\begin{equation}\label{eq:adjoint}
  -\dot{\lambda} + A^* \lambda = h(t),\quad T\geq t \geq 0,\quad \lambda(T)=0,
\end{equation}
where the functions $\lambda(t)$ and $h(t)$ are in ${\mathbb
  C}^D$. Note that the adjoint equation is solved backwards in time
from the terminal condition $\lambda(T)=0$.
%
\begin{lemma}[Adjoint relation]\label{lem:ad}
  Let $\Phi(t)$ be the solution of the state equation \eqref{eq:state} with forcing function $f(t)$
  and let $\lambda(t)$ be the solution of the adjoint state equation \eqref{eq:adjoint} with forcing
  function $h(t)$. The solutions and forcing functions satisfy the adjoint relation
  \begin{equation}\label{adjoint-rel}
    (f, \lambda) = (\Phi, h).
  \end{equation}
\end{lemma}
%
\paragraph{Proof:}
From \eqref{eq:state}, $f=\dot{\Phi} + A(\alpha) \Phi$, which we insert into the left hand side of
\eqref{adjoint-rel}. By integration by parts in time,
\[
( \dot{\Phi} + A \Phi, \lambda ) = \left.\langle \Phi(\tau), \lambda(\tau)
\rangle\right|_{0}^T -
%
( \Phi , \dot{\lambda} ) +  ( \Phi, A^* \lambda ) = (\Phi, - \dot{\lambda} +
A^* \lambda).
\]
The boundary term is zero because $\Phi(0)=0$ and $\lambda(T)=0$. From \eqref{eq:adjoint}, $h =
-\dot{\lambda} + A^* \lambda$, which proves the lemma. $\square$

The adjoint relation can be used to calculate the gradient of the objective functional
\eqref{eq:grad-formula}. The function $\Phi_k(t)$ satisfies \eqref{eq:state} with forcing $f_k(t) = -
\partial A/\partial \alpha_k\,\Psi^\alpha(t)$. By taking the forcing in the adjoint equation
\eqref{eq:adjoint} to be $h(t) = \Psi^\alpha(t)- d(t)$, it becomes
\begin{equation}\label{our-adjoint}
-\dot{\lambda} + A^* \lambda = \Psi(t)- d(t),\quad T\geq t \geq 0,\quad \lambda(T)=0.
\end{equation}
Lemma~\ref{lem:ad} gives
\[
\frac{\partial J}{\partial \alpha_k} = 2\, {\rm Re} \left( \Phi_k, h \right) =
%
2\, {\rm Re} \left( f_k, \lambda \right) =
%
-2\, {\rm Re} \left( \frac{\partial A}{\partial \alpha_k} \Psi^\alpha, \lambda \right).
\]
The advantage of using the adjoint relation is that all components of the gradient can be calculated
from $\Psi^\alpha(t)$ and $\lambda(t)$, i.e., by solving one state equation and one adjoint state
equation, we can compute the gradient with respect to any number of parameters, $M$.

\section{The quantum control problem}

The solution of the state equation \eqref{eq:ode} can formally be written
\[
\Psi(t) = U(t,\alpha)\Psi(0),\quad U(t,\alpha) = \exp\left(-i\int_0^t H(\tau,\alpha)\, d\tau \right).
\]
Because $H=H^*$, the solution operator is unitary, $U^* U = I$.

A quantum gate uses control functions to transform a basis of initial data
\[
\Psib(0):=\left[ \Psi_0(0), \Psi_1(0),\ldots, \Psi_{D-1}(0)\right]= \begin{bmatrix}
  1 & 0 &    & & \\
  0 & 1 & 0 & & \\
  & \ddots & \ddots & \ddots &\\
  &       & 0 & 1 & 0\\
  &       &    & 0 & 1
  \end{bmatrix}
\]
to some desired target state
\[
\Psib^t(T):=\left[ \Psi^t_0(T), \Psi^t_1(T),\ldots, \Psi^t_{D-1}(T)\right]=: G_t\Psib(0)= G_t,\quad G_t^* G_t=I.
\]
Here, the complex $D\times D$ matrix $G_t$ represents the target gate. Because the solution operator
$U(t,\alpha)$ is unitary for all $\alpha$, assuming that the control problem has a solution, the
target state must be a unitary transformation of the initial data, implying that $G_t$ is a unitary
matrix. Examples of quantum gates include the Hadamard, Pauli, controlled NOT (CNOT) and the Toffoli
(CCNOT) gates.

Given the parameter vector $\alpha$, we can integrate the state equation \eqref{eq:ode} for each
set of initial data in $\Psib(0)$. The resulting transformation is denoted
\[
\Psib^\alpha(T) = G_\alpha \Psib(0) = G_\alpha.
\]

\subsection{Objective functionals}
The objective functional must measure the distance between a target gate matrix, $G_t$, and the
realized gate matrix, $G_\alpha$. If $G_\alpha=G_t$, then the Frobenious matrix norm satisfies
\[
\| G_t \|^2_F = \langle G_t, G_t \rangle_F = Tr(G_t^* G_t) = Tr(I) = D.
\]
Furthermore,
\[
|\langle  G_\alpha,G_t \rangle_F | \leq \|G_\alpha\|_F \|G_t\|_F = D.
\]
These observations indicate that the functional
\begin{equation}\label{eq_trace-linear}
c_1 := 1 - \frac{1}{D} |Tr (G_\alpha^* G_t)| =  1 - \frac{1}{D} |\langle G_\alpha, G_t\rangle_F|
\end{equation}
could be an appropriate candidate for the quantum control problem. However, consider the (slightly
weird) one-dimensional case ($D=1$) with $G_t=1$ and $G_\alpha=x$. Then $G_\alpha^* G_t = x^*$ and
$|Tr (G_\alpha^* G_t)| = |x|$. This functional is not differentiable at $x=0$ and might cause
convergence problems with gradient-based minimization algorithms.

A better choice might be
\begin{equation}\label{eq_trace-squared}
c_2 := 1 - \frac{1}{D^2} |Tr (G_\alpha^* G_t)|^2 = 1 - \frac{1}{D^2} \langle G_\alpha, G_t \rangle_F
\langle G_t,  G_\alpha \rangle_F,
\end{equation}
but it is not obvious what properties of $G_\alpha$ it actually measures. To gain more insight,
consider the functional
\begin{multline}\label{eq_trace-real}
  c_3 := \| G_\alpha-G_t \|_F^2 = \langle G_\alpha-G_t, G_\alpha-G_t \rangle_F = \\
  %
  \langle G_\alpha, G_\alpha \rangle_F - \langle G_\alpha, G_t \rangle_F  -
  \langle G_t, G_\alpha \rangle_F + \langle G_t, G_t \rangle_F =\\
  %
  2D - 2{\rm Re}\, \langle G_\alpha, G_t \rangle_F = 2D\left( 1 - \frac{1}{D} {\rm Re}\, \langle
  G_\alpha, G_t \rangle_F\right). 
\end{multline}
This functional clearly has a global minima at $G_\alpha=G_t$. It shares simularities with
\eqref{eq_trace-linear}, but instead of taking the magnitude of the trace, we here take its real
part. It may be more convenient to work with the expression on left hand
side, because the Frobenious matrix scalar product satisfies
\[
\langle A, B \rangle_F = Tr(A^* B) = \sum_{j=0}^{D-1} \langle A\eb_j, B\eb_j\rangle,
\]
where $\eb_j$ is the $j^{th}$ unit vector. By taking $A=B=G_\alpha - G_t$,
\[
(G_\alpha - G_t)\eb_j = G_\alpha\eb_j - G_t\eb_j = \Psi_j^\alpha(T) - \Psi_j^t(T).
\]
Thus,
\[
c_3 = \sum_{j=0}^{D-1} |(G_\alpha - G_t)\eb_j|^2 = \sum_{j=0}^{D-1} \left| \Psi_j^\alpha(T) -
\Psi_j^t(T) \right|^2.
\]
We can generalize the $c_3$ functional to be
\begin{equation}
g_3(\Psib^\alpha) =  \sum_{j=0}^{D-1} \int_0^T w(\tau) \left| \Psi_j^\alpha(\tau) - \Psi_j^t(\tau)
\right|^2\, d\tau,\quad w(t) \geq 0. 
\end{equation}
Here, $w(t)$ is a weight function with $w(0)=0$, $w(T)=1$. It is monotonically increasing in time
and localized near $t=T$. By defining $d_j(t)=\Psi_j^t(t)$, we see that this functional is a
vectorized version of the simple functional \eqref{eq_func-simple}. The gradient of $g_3$ with
respect to all components of $\alpha$ can therefore be calculated by solving one state and one
adjoint wave equation for each $j$.

The objective functionals that was implemented last spring is
\[
g_4(\Psib^\alpha) := \sum_{j=0}^{D-1} \int_0^T w(\tau)  \left( |\Psi^\alpha_j(\tau)|^2 - |d_j(\tau)|^2 \right)^2\,
d\tau,\quad w(t) \geq 0,
\]
It does not consider the relative phases of $\Psi_j$ and would probably not be very useful in practice.

\begin{remark}
In many cases the absolute phase of the gate matrix is irrelevant. This means that the
objective functional should be invariant to transformations $G_t \to \exp(i\beta) G_t$, for any real
phase angle $\beta$.
\end{remark}


\end{document}

